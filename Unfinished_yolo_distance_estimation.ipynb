{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74d63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, target_height, target_width):\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def process_images(self, images):\n",
    "        # Resize\n",
    "        images = self._resize_images(images)\n",
    "        # Normalize\n",
    "        images = self._normalize_images(images)\n",
    "        return images\n",
    "\n",
    "    def process_depths(self, depths):\n",
    "        # Resize\n",
    "        depths = self._resize_images(depths)\n",
    "        # Normalize\n",
    "        depths = self._normalize_depths(depths)\n",
    "        # Expand dimensions\n",
    "        depths = np.expand_dims(depths, -1)  # Add an extra dimension for the 'channels'\n",
    "        return depths\n",
    "\n",
    "    def _resize_images(self, images):\n",
    "        return np.array([cv2.resize(img, (self.target_width, self.target_height)) for img in images])\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        # Images are normalized to [0, 1] interval\n",
    "        return images / 255.0\n",
    "\n",
    "    def _normalize_depths(self, depths):\n",
    "        # Depths are normalized to [0, 1] interval\n",
    "        return depths / np.max(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9088395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Object bicycle is at a depth of 0.25919607281684875\n",
      "Object bicycle is at a depth of 0.25910496711730957\n",
      "Object bicycle is at a depth of 0.2819024920463562\n",
      "Object tv is at a depth of 0.2132578194141388\n",
      "Object truck is at a depth of 0.317163348197937\n",
      "Object dog is at a depth of 0.2045358568429947\n",
      "Object dog is at a depth of 0.20351308584213257\n",
      "Object dog is at a depth of 0.2080395519733429\n",
      "Object dog is at a depth of 0.1978648155927658\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "preprocessor = Preprocessor(256, 256)\n",
    "\n",
    "# Load YOLOv3 model\n",
    "yolo = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\") \n",
    "layer_names = yolo.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in yolo.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load names of classes and get random colors\n",
    "classes = open('coco.names').read().strip().split('\\n')\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\n",
    "\n",
    "# Load U-Net model\n",
    "unet = tf.keras.models.load_model('depth_model') \n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"dog.jpg\")\n",
    "image = cv2.resize(image, (256, 256))\n",
    "height, width, channels = image.shape\n",
    "image_extend = np.expand_dims(image, axis=0)  # add an extra dimension\n",
    "image_processed = preprocessor.process_images(image_extend)\n",
    "\n",
    "# Detect objects with YOLOv3\n",
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (256, 256), (0, 0, 0), True, crop=False)\n",
    "yolo.setInput(blob)\n",
    "outs = yolo.forward(output_layers)\n",
    "\n",
    "# Estimate depth with U-Net\n",
    "depth_map = unet.predict(image_processed)\n",
    "\n",
    "# Calculate distances\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.7: # you can adjust this threshold\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            \n",
    "            # Calculate average depth within bounding box\n",
    "            single_depth_map = depth_map[0, :, :, 0]\n",
    "            depth = np.mean(single_depth_map[y:y+h, x:x+w])\n",
    "            print(f\"Object {str(classes[class_id])} is at a depth of {depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d29fca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.546643757637337"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = 0.0036*(0.31212911009788513**2) - 0.5373*0.31212911009788513 + 21.714\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd50d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
